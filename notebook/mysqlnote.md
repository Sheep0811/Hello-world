# 数据库笔记

## **存储引擎**

* **InnoDB特点**

  ​		**InnoDB存储引擎**：InnoDB的数据文件本身就是索引文件，叶节点data域保存了完整的数据记录；

  ​		辅助索引：对于辅助索引的结构如下，与主键索引不同的是，叶节点的data存放存放主键索引的值，而不是地址，因此辅助索引进行检索时需要检索两遍索引,首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。

　　　　InnoDB支持事务操作，即commit，rollback和crash-recovery；

　　　　InnoDB支持行级锁，即可以给一行数据上锁；

　　　　InnoDB支持外键关系约束；

- **MyISAM特点**

 　　 MyISAM 适合读取操作较多的数据表，其读取速度较快；

　　　	**MyISAM存储引擎**：MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址（叶节点data域）。

​				使用辅助索引与主键索引结构相同；

　　　　MyISAM支持表级锁，可以给一张表上锁；

　　　　MyISAM支持全文索引；

　　　　MyISAM 支持Gometry，Point等表示空间位置的数据类型；

## InnoDB与MyISAM区别

- InnoDB数据文件即包含主键索引，所以InnoDB要求表必须有主键，如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键。而且不建议使用过长的字段作为主键，因为所有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大。另外，用非单调的字段作为主键在InnoDB中也不建议，因为InnoDB数据文件本身是一颗B+Tree，非单调的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择。

1. InnoDB支持事务，MyISAM不支持，对于InnoDB每一条SQL语言都默认封装成事务，自动提交，这样会影响速度，所以最好把多条SQL语言放在begin和commit之间，组成一个事务； 

2. InnoDB支持外键，而MyISAM不支持。对一个包含外键的InnoDB表转为MYISAM会失败； 

3. InnoDB是聚集索引，使用B+Tree作为索引结构，数据文件是和（主键）索引绑在一起的（表数据文件本身就是按B+Tree组织的一个索引结构），必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。


> MyISAM是非聚集索引，也是使用B+Tree作为索引结构，索引和数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。
>
> 也就是说：InnoDB的B+树主键索引的叶子节点就是数据文件，辅助索引的叶子节点是主键的值；而MyISAM的B+树主键索引和辅助索引的叶子节点都是数据文件的地址指针。

4. InnoDB不保存表的具体行数，执行select count(*) from table时需要全表扫描。而MyISAM用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快（注意不能加有任何WHERE条件）；

​		那么为什么InnoDB没有了这个变量呢？

>因为InnoDB的事务特性，在同一时刻表中的行数对于不同的事务而言是不一样的，因此count统计会计算对于当前事务而言可以统计到的行数，而不是将总行数储存起来方便快速查询。InnoDB会尝试遍历一个尽可能小的索引除非优化器提示使用别的索引。如果二级索引不存在，InnoDB还会尝试去遍历其他聚簇索引。
>如果索引并没有完全处于InnoDB维护的缓冲区（Buffer Pool）中，count操作会比较费时。可以建立一个记录总行数的表并让你的程序在INSERT/DELETE时更新对应的数据。和上面提到的问题一样，如果此时存在多个事务的话这种方案也不太好用。如果得到大致的行数值已经足够满足需求可以尝试SHOW TABLE STATUS


5. Innodb不支持全文索引，而MyISAM支持全文索引，在涉及全文索引领域的查询效率上MyISAM速度更快高；PS：5.7以后的InnoDB支持全文索引了

6. MyISAM表格可以被压缩后进行查询操作

7. InnoDB支持表、行(默认)级锁，而MyISAM支持表级锁

   > InnoDB的行锁是实现在索引上的，而不是锁在物理行记录上。潜台词是，如果访问没有命中索引，也无法使用行锁，将要退化为表锁。

例如：

    t_user(uid, uname, age, sex) innodb;
     
    uid PK
    无其他索引
    update t_user set age=10 where uid=1;             命中索引，行锁。
     
    update t_user set age=10 where uid != 1;           未命中索引，表锁。
     
    update t_user set age=10 where name='chackca';    无索引，表锁。


8、InnoDB表必须有唯一索引（如主键）（用户没有指定的话会自己找/生产一个隐藏列Row_id来充当默认主键），而Myisam可以没有

9、Innodb存储文件有frm、ibd，而Myisam是frm、MYD、MYI

        Innodb：frm是表定义文件，ibd是数据文件
    
        Myisam：frm是表定义文件，myd是数据文件，myi是索引文件

如何选择：
    1. 是否要支持事务，如果要请选择innodb，如果不需要可以考虑MyISAM；
    1. 如果表中绝大多数都只是读查询，可以考虑MyISAM，如果既有读也有写，请使用InnoDB。

3. 系统奔溃后，MyISAM恢复起来更困难，能否接受；

4. MySQL5.5版本开始Innodb已经成为Mysql的默认引擎(之前是MyISAM)，说明其优势是有目共睹的，如果你不知道用什么，那就用InnoDB，至少不会差。


InnoDB为什么推荐使用自增ID作为主键？

> 答：自增ID可以保证每次插入时B+索引是从右边扩展的，可以避免B+树和频繁合并和分裂（对比使用UUID）。如果使用字符串主键和随机主键，会使得数据随机插入，效率比较差。


innodb引擎的4大特性

> 插入缓冲（insert buffer),二次写(double write),自适应哈希索引(ahi),预读(read ahead)

### Memory

将数据存在内存，为了提高数据的访问速度，每一个表实际上和一个磁盘文件关联。文件是frm。

（1）支持的数据类型有限制，比如：不支持TEXT和BLOB类型，对于字符串类型的数据，只支持固定长度的行，VARCHAR会被自动存储为CHAR类型；

（2）支持的锁粒度为表级锁。所以，在访问量比较大时，表级锁会成为MEMORY存储引擎的瓶颈；

（3）由于数据是存放在内存中，一旦服务器出现故障，数据都会丢失；

（4）查询的时候，如果有用到临时表，而且临时表中有BLOB，TEXT类型的字段，那么这个临时表就会转化为MyISAM类型的表，性能会急剧降低；

（5）默认使用hash索引。

（6）如果一个内部表很大，会转化为磁盘表。

## 索引

B-树是一种平衡的多路查找(又称排序)树，在文件系统中有所应用。主要用作文件的索引。其中的B就表示平衡(Balance)

**B+树有一个最大的好处，方便扫库**，B树必须用中序遍历的方法按序扫库，而B+树直接从叶子结点挨个扫一遍就完了。

B+树支持range-query(区间查询)非常方便，而B树不支持。这是数据库选用B+树的最主要原因。

比如要查 5-10之间的，B+树一把到5这个标记，再一把到10，然后串起来就行了，B树就非常麻烦。**B树的好处，就是成功查询特别有利，因为树的高度总体要比B+树矮。**不成功的情况下，B树也比B+树稍稍占一点点便宜。

B树的优势是当你要查找的值恰好处在一个非叶子节点时，查找到该节点就会成功并结束查询，而B+树由于非叶节点只是索引部分，这些节点中只含有其子树中的最大(或最小)关键字，当非终端节点上的关键字等于给点值时，查找并不终止，而是继续向下直到叶子节点。因此在B+树中，无论查找成功与否，都是走了一条从根到叶子节点的路径。

有很多基于频率的搜索是选用B树，越频繁query的结点越往根上走，前提是需要对query做统计，而且要对key做一些变化。

1. **索引作用**

　　当我们在数据库表中查询数据时，若没有索引，会逐个遍历表格中的所有记录，表格中数据记录量大时很耗时。建立索引就像创建目录一样，直接通过索引找到数据存储位置，加快查找。例如：有一张person表，其中有2W条记录，记录着2W个人的信息。有一个Phone的字段记录每个人的电话号码，现在想要查询出电话号码为xxxx的人的信息。

　　如果没有索引，那么将从表中第一条记录一条条往下遍历，直到找到该条信息为止。

　　如果有了索引，那么会将该Phone字段，通过一定的方法进行存储，好让查询该字段上的信息时，能够快速找到对应的数据，而不必在遍历2W条数据了。其中MySQL中的索引的存储类型有两种：BTREE、HASH。 也就是用树或者Hash值来存储该字段，要知道其中详细是如何查找的，就需要会算法的知识了。

　	但索引也不是越多越好，因为创建的索引也需要占用空间，而且需要维护索引，因此没必要为所有字段创建索引，对于经常需要查询，或数据记录很多的字段可以创建索引。

### **索引分类(index或key)**

按数据结构分类可分为：**B+tree索引、Hash索引、Full-text索引**。
按物理存储分类可分为：**聚簇索引、二级索引（辅助索引）**。
按字段特性分类可分为：**主键索引、普通索引、前缀索引**。
按字段个数分类可分为：**单列索引、联合索引（复合索引、组合索引）**。

**按数据结构分类**

MySQL索引按数据结构分类可分为：**B+tree索引、Hash索引、Full-text索引**。

| -             | InnoDB         | MyISAM | Memory |
| ------------- | -------------- | ------ | ------ |
| B+tree索引    | √              | √      | √      |
| Hash索引      | ×              | ×      | √      |
| Full-text索引 | √（MySQL5.6+） | √      | ×      |

> 注：InnoDB实际上也支持Hash索引，但是InnoDB中Hash索引的创建由存储引擎引擎自动优化创建，不能人为干预是否为表创建Hash索引

- **索引是在存储引擎中实现的，也就是说不同的存储引擎，会使用不同的索引**

  MyISAM和InnoDB存储引擎：只支持BTREE索引， 也就是说默认使用BTREE，不能够更换

　　MEMORY/HEAP存储引擎：支持HASH和BTREE索引

- 索引我们分为四类来讲 单列索引(普通索引，唯一索引，主键索引)、组合索引、全文索引、空间索引、

  	1. **单列索引：一个索引只包含单个列，但一个表中可以有多个单列索引。**
		
  	 　	2. **普通索引, INDEX**：MySQL中基本索引类型，没有什么限制，允许在定义索引的列中插入重复值和空值，纯粹为了查询数据更快一点。
  	           　	3. 唯一索引,UNIQUE** ：索引列中的值必须是唯一的，但是允许为空值，　　　

  　　4. **主键索引， PRIMARY KEY**：是一种特殊的唯一索引，不允许有空值。　　　　　　　　　

           5. **组合索引:** 在表中的多个字段组合上创建的索引，只有在查询条件中使用了这些字段的左边字段时，索引才会被使用，使用组合索引时遵循最左前缀集合。
              . **全文索引 FULLTEXT :**只有在MyISAM引擎上才能使用 (MySQL 5.6版本的InnoDB 开始支持全文索引)，只能在CHAR,VARCHAR,TEXT类型字段上使用全文索引，介绍了要求，说说什么是全文索引，就是在一堆文字中，通过其中的某个关键字等，就能找到该字段所属的记录行.
  　　5. **空间索引 SPATIAL :** 只有在MyISAM引擎上才能使用（MySQL 5.7版本的InnoDB 开始支持)**，**空间索引是对空间数据类型（坐标，地理位置等）的字段建立的索引，MySQL中的空间数据类型有四种，GEOMETRY、POINT、LINESTRING、POLYGON。**创建空间索引的列，必须将其声明为NOT NULL**

- 另外索引也可以分为聚集索引和非聚集索引：
  	7. **聚集（clustered）索引**：数据行的物理顺序与列值（一般是主键的那一列）的逻辑顺序相同，一个表中只能拥有一个聚集索引。（即主键索引）
       　	8. **非聚集索引(**辅助索引)：该索引中索引的逻辑顺序与磁盘上行的物理存储顺序不同，一个表中可以拥有多个非聚集索引。（包括普通索引，唯一索引，全文索引等）

### 索引失效

**索引失效的原因：**

如果是同样的sql如果在之前能够使用到索引，那么现在使用不到索引，以下几种主要情况:

> 1. 随着表的增长，where条件出来的数据太多，大于15%，使得索引失效（会导致CBO计算走索引花费大于走全表）
> 2. 统计信息失效 需要重新搜集统计信息
> 3. 索引本身失效 需要重建索引

具体情况：

**1.单独引用复合索引里非第一位置的索引列**

> 假如有INDEX(a,b,c)，
> 当条件为a或a,b或a,b,c时都可以使用索引，
> 但是当条件为b,c时将不会使用索引。
>
> **复合索引遵守“最左前缀”原则，即在查询条件中使用了复合索引的第一个字段，索引才会被使用。**因此，在复合索引中索引列的顺序至关重要。如果不是按照索引的最左列开始查找，则无法使用索引。

2.**对索引列运算**，运算包括（+、-、*、/、！、<>、%、**like’%_’（%放在前面）**、or、in、exist等），导致索引失效。

> 错误的例子：select * from test where id-1=9;
> 正确的例子：select * from test where id=10;
> **注意！！**
> mysql sql 中如果使用了 **not in ， not exists ， （<> 不等于 ！=） 这些不走**
> < 小于 > 大于 <= >= 这个根据实际查询数据来判断，**如果全盘扫描速度比索引速度要快则不走索引** 。

3.**对索引应用内部函数**，这种情况下应该建立基于函数的索引。

> select * from template t where ROUND(t.logicdb_id) = 1
> 此时应该建ROUND(t.logicdb_id)为索引。

4.**类型错误**，如字段类型为varchar，where条件用number。

> 例：template_id字段是varchar类型。
>
> 错误写法：select * from template t where t.template_id = 1
>
> 正确写法：select * from template t where t.template_id = ‘1’

5.**如果MySQL预计使用全表扫描要比使用索引快，则不使用索引**
6.**like的模糊查询以%开头，索引失效**
7.**索引列没有限制 not null**，索引不存储空值，如果不限制索引列是not null，oracle会认为索引列有可能存在空值，所以不会按照索引计算

### 索引的优缺点

**优点：**

> 第一，通过创建**唯一性索引**，可以保证数据库表中每一行**数据的唯一性**。
> 第二，可以大大**加快 数据的检索速度**，这也是创建索引的最主要的原因。
> 第三，可以**加速表和表之间的连接**，特别是在实现数据的**参考完整性**方面特别有意义。
> 第四，在使用分组和排序子句进行数据检索时，同样可以显著**减少查询中分组和排序的时间。**
> 第五，通过使用索引，可以在查询的过程中，使用**优化隐藏器，提高系统的性能**。

**覆盖索引的好处**

> **如果一个索引包含所有需要的查询的字段的值，直接根据索引的查询结果返回数据，而无需读表，能够极大的提高性能**。因此，可以定义一个让索引包含的额外的列，即使这个列对于索引而言是无用的。

**缺点：**

> 第一，**创建索引和维护索引要耗费时间**，这种时间随着数据量的增加而增加；
>
> 第二，**索引需要占物理空间**，**除了数据表占数据空间之外，每一个索引还要占一定的物理空间**，如果要建立聚簇索引，那么需要的空间就会更大，如果非聚集索引很多，一旦聚集索引改变，那么所有非聚集索引都会跟着变；
>
> 第三，当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，一旦一个数据改变，并且改变的列比较多，可能会引起好几个索引跟着改变，这样就**降低了数据的维护速度**。
>
> 第四、每个索引都有统计信息，索引越多统计信息越多，**过多索引会导致优化器优化过程需要评估的组合增多**。创建索引的时候，应该仔细考虑在哪些列上可以创建索引，在哪些列上不能创建索引。

### 如何选择合适的列创建索引

1 在**经常需要搜索的列**上，可以加快搜索的速度；

2 在**作为主键的列**上，**强制该列的唯一性和组织表中数据的排列结构**；

3 在**经常用在连接的列**上，这些列主要是一些外键，可以**加快连接的速度**；

4 在**经常需要根据范围进行搜索的列上创建索引**，因为索引已经排序，其指定的范围是连续的；这样查询可以利用索引的排序，加快排序查询时间；

5 在**经常使用在WHERE子句中的列上面创建索引，加快条件的判断速度**。当增加索引时，会提高检索性能，但是会降低修改性能

6 **唯一性很差的字段不合适做索引**，如性别

7 **更新频繁的字段不适合**，耗时且影响性能

### 最左匹配原则的原理
如果有一个 2 列的索引 (a, b)，则已经对 (a)、(a, b) 上建立了索引；
如果有一个 3 列索引 (a, b, c)，则已经对 (a)、(a, b)、(a, b, c) 上建立了索引；

**最左前缀匹配原则：**以最左边的为起点任何连续的索引都能匹配上。同时遇到范围查询(>、<、between、like)就会停止匹配。
例如：如果建立(a,b)顺序的索引，我们的条件只有b=xxx，是匹配不到(a,b)索引的；

但是如果查询条件是a = 1 and b = 2或者b=2 and a=1就可以，因为优化器会自动调整a,b的顺序，并不需要严格按照索引的顺序来；

再比如a = 1 and b = 2 and c > 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，因为c字段是一个范围查询，它之后的字段会停止匹配　　

要想理解联合索引的最左匹配原则，先来理解下索引的底层原理。索引的底层是一颗B+树，那么联合索引的底层也就是一颗B+树，只不过联合索引的B+树节点中存储的是键值。由于构建一棵B+树只能根据一个值来确定索引关系，所以数据库依赖联合索引最左的字段来构建。

举例：创建一个（a,b）的联合索引，那么它的索引树就是下图的样子。

![img](https://img2020.cnblogs.com/blog/1804577/202005/1804577-20200521182659976-48843100.png)

 　可以看到a的值是有顺序的，1，1，2，2，3，3，而b的值是没有顺序的1，2，1，4，1，2。但是我们又可发现a在等值的情况下，b值又是按顺序排列的，但是这种顺序是相对的。这是因为MySQL创建联合索引的规则是首先会对联合索引的最左边第一个字段排序，在第一个字段的排序基础上，然后在对第二个字段进行排序。所以b=2这种查询条件没有办法利用索引。

### 覆盖索引

如果一个索引包含所有需要的查询的字段的值，我们称之为覆盖索引。覆盖索引是非常有用的工具，能够极大的提高性能。因为，只需要读取索引，而无需读表，极大减少数据访问量，这也是不建议使用Select * 的原因。

## ACID

https://mp.weixin.qq.com/s/lbh7tJIANFsYRi_xfCpwJg

- **原子性（Atomicity）**：一个事务中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节，而且事务在执行过程中发生错误，会被回滚到事务开始前的状态，就像这个事务从来没有执行过一样；
- **一致性（Consistency）**：数据库的完整性不会因为事务的执行而受到破坏，比如表中有一个字段为姓名，它有唯一约束，也就是表中姓名不能重复，如果一个事务对姓名字段进行了修改，但是在事务提交后，表中的姓名变得非唯一性了，这就破坏了事务的一致性要求，这时数据库就要撤销该事务，返回初始化的状态。
- **隔离性（Isolation）**：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。
- **持久性（Durability）**：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。

> InnoDB 引擎通过什么技术来保证事务的这四个特性的呢？

- 持久性是通过 **redo log** （重做日志）来保证的；
- 原子性是通过 **undo log**（回滚日志）来保证的；
- 隔离性是通过 **MVCC**（多版本并发控制）或锁机制来保证的；
- 一致性则是通过持久性+原子性+隔离性来保证；

## 并发引起的问题

同时处理多个事务时，就可能出现**脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）**的问题。

- **脏读**

​	如果一个事务「读到」了另一个「未提交事务修改过的数据」，就意味着发生了「脏读」现象。

- **不可重复读**

​	在一个事务内多次读取同一个数据，如果出现前后两次读到的数据不一样的情况，就意味着发生了「不可重复读」现象。

- **幻读**

​	在一个事务内多次查询某个符合查询条件的「记录数量」，如果出现前后两次查询到的记录数量不一样的情况，就意味着发生了「幻读」现象。

这三个现象的严重性排序：脏读 > 不可重复读 > 幻读

## 隔离级别

SQL 标准提出了四种隔离级别来规避这些现象，隔离级别越高，性能效率就越低，这四个隔离级别如下：

- **读未提交（\*read uncommitted\*）**，指一个事务还没提交时，它做的变更就能被其他事务看到；
- **读已提交（\*read committed\*）**，指一个事务提交之后，它做的变更才能被其他事务看到；
- **可重复读（\*repeatable read\*）**，指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，**MySQL InnoDB 引擎的默认隔离级别**；
- **串行化（\*serializable\* ）**；会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行；

针对不同的隔离级别，并发事务时可能发生的现象也会不同。

- 在「读未提交」隔离级别下，可能发生脏读、不可重复读和幻读现象；
- 在「读提交」隔离级别下，可能发生不可重复读和幻读现象，但是不可能发生脏读现象；
- 在「可重复读」隔离级别下，可能发生幻读现象，但是不可能脏读和不可重复读现象；
- 在「串行化」隔离级别下，脏读、不可重复读和幻读现象都不可能会发生。

所以，**要解决脏读现象，就要升级到「读提交」以上的隔离级别；要解决不可重复读现象，就要升级到「可重复读」的隔离级别**。

不过，要解决幻读现象不建议将隔离级别升级到「串行化」，因为这样会导致数据库在并发事务时性能很差。

**InnoDB 引擎的默认隔离级别虽然是「可重复读」，但是它通过next-key lock 锁（行锁和间隙锁的组合）来锁住记录之间的“间隙”和记录本身，防止其他事务在这个记录之间插入新的记录，这样就避免了幻读现象。**

## CAP原则

![img](https://img2018.cnblogs.com/blog/285763/201906/285763-20190621144256061-464757033.png)

 

　　CAP原则又称CAP定理，指的是在一个分布式系统中， Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），三者不可得兼。

　　CAP原则是NOSQL数据库的基石。

分布式系统的CAP理论：理论首先把分布式系统中的三个特性进行了如下归纳：

- **一致性（C）**：在分布式系统中的所有数据备份，在同一时刻是否同样的值。（等同于所有节点访问同一份最新的数据副本）
- **可用性（A）**：在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求。（对数据更新具备高可用性）
- **分区容忍性（P）**：以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择。

CAP三个特性只能满足其中两个，那么取舍的策略就共有三种：

**CA without P：**如果不要求P（不允许分区），则C（强一致性）和A（可用性）是可以保证的。但放弃P的同时也就意味着放弃了系统的扩展性，也就是分布式节点受限，没办法部署子节点，这是违背分布式系统设计的初衷的。传统的关系型数据库RDBMS：Oracle、MySQL就是CA。

**CP without A：**如果不要求A（可用），相当于每个请求都需要在服务器之间保持强一致，而P（分区）会导致同步时间无限延长(也就是等待数据同步完才能正常访问服务)，一旦发生网络故障或者消息丢失等情况，就要牺牲用户的体验，等待所有数据全部一致了之后再让用户访问系统。设计成CP的系统其实不少，最典型的就是分布式数据库，如Redis、HBase等。对于这些分布式数据库来说，数据的一致性是最基本的要求，因为如果连这个标准都达不到，那么直接采用关系型数据库就好，没必要再浪费资源来部署分布式数据库。

 **AP wihtout C：**要高可用并允许分区，则需放弃一致性。一旦分区发生，节点之间可能会失去联系，为了高可用，每个节点只能用本地数据提供服务，而这样会导致全局数据的不一致性。典型的应用就如某米的抢购手机场景，可能前几秒你浏览商品的时候页面提示是有库存的，当你选择完商品准备下单的时候，系统提示你下单失败，商品已售完。这其实就是先在 A（可用性）方面保证系统可以正常的服务，然后在数据的一致性方面做了些牺牲，虽然多少会影响一些用户体验，但也不至于造成用户购物流程的严重阻塞。

## CAS思想

其实数据库乐观锁的具体实现几乎就跟Java中乐观锁采用的CAS算法思想是一致，所以我们可以从CAS算法中学习到数据库乐观锁的设计：

CAS指令全称为Compare and Swap，它是系统的指令集，**整个CAS操作是一个原子操作，是不可分割的。**从具体的描述上，我们可以这么看CAS操作：

**CAS指令需要3个操作数，分别是内存位置V，旧的预期值A,和新值B。CAS指令执行时，当我们读取的内置位置V的现值等于旧预期值A时，处理器才会将新值B去更新内置位置V的值。否则它就不执行更新，但无论是否更新V的值，都会返回V的旧值。**

>  我们通俗的放到代码层次上去理解i = 2; i++，就是说：
>
>  1. 首先线程1从内存位置V中读取到了值，保存并作为旧预期值A. (v = 2 ,a = 2)
>  2. 然后在因为i要进行++操作，系统会比较内存位置V的现值跟旧预期值A进行比较，既V =? A。
>  3. 如果相等，B = i++ = 3 ，新值B就会对内存位置V进行更新，所以内存位置V的值就变成了B的值，3
>  4. 如果不相等，则说明有其他的线程修改过了内存位置V的值，比如线程2在线程1修改i的值前就更新了i的值。所以线程1会更新变量i失败。但线程不会挂起，而是返回失败状态，等待调用线程决定是否重试或其他操作。(通常会重试直到成功)

数据库层的乐观锁实现也类似代码层面的实现

## 乐观锁、悲观锁与MVCC

**数据库并发场景有三种，分别为：**

- `读-读`：不存在任何问题，也不需要并发控制
- `读-写`：有隔离性问题，可能遇到脏读，幻读，不可重复读
- `写-写`：可能存更新丢失问题，比如第一类更新丢失，第二类更新丢失

**乐观锁和悲观锁的澄清**

- 无论是悲观锁还是乐观锁，他们本质上不是数据库中具体的锁概念，而是我们定义出来，用来描述两种类别的锁的思想。所以有了设计的分类，我们就可以通过这个分类去对数据库中具体的锁进行分门别类；
- 不过数据库中的**乐观锁更倾向叫乐观并发控制（OCC），悲观锁叫悲观并发控制（PCC），还有区别于乐观悲观锁的一种控制叫MVCC，多版本并发控制**
- 也不要把乐观锁和悲观锁与数据库中的行锁，表锁，排他锁，共享锁混为一谈，他们并不是一个维度的东西；前者是一个锁思想，可以将后者根据是否进行趋近于乐观或悲观锁的思想进行分类
- 乐观锁和悲观锁的概念不仅仅存在于数据库领域，可以说存在线程安全，存在并发的场景几乎都有乐观锁和悲观锁的适用场景，比如Java中也有乐观锁和悲观锁思想的具体实现；但不同领域的乐观和悲观锁的具体实现都不尽相同，要解决的问题也可能有所不一样

### **什么是悲观锁？**

在关系数据库管理系统里，悲观并发控制（又名“悲观锁”，Pessimistic Concurrency Control，缩写“PCC”）是一种并发控制的方法; 悲观锁指的是采用一种持悲观消极的态度，默认数据被外界访问时，必然会产生冲突，所以在数据处理的整个过程中都采用加锁的状态，保证同一时间，只有一个线程可以访问到数据，实现数据的排他性；通常，数据库的悲观锁是利用数据库本身提供的锁机制去实现的.

数据库的**悲观并发控制可以解决读-写冲突和写-写冲突**,指在用加锁的方式去解决

**悲观锁的实现**

> 通常情况下，数据库的悲观锁就是利用数据库本身提供的锁去实现的

- 外界要访问某条数据，那它就要首先向数据库申请该数据的锁(某种锁)
- 如果获得成功，那它就可以操作该数据，在它操作期间，其他客户端就无法再操作该数据了
- 如果获得失败，则代表同一时间已有其他客户端获得了该锁，那就必须等待其他客户端释放锁
- 当然数据库提供了非常多的锁，每种数据库提供的锁也不尽然相同，所以具体情况就要看是什么锁了,比如行锁，表锁等

**优点与缺点**

> 悲观并发控制实际上是“先取锁再访问”的保守策略，为数据处理的安全提供了保证。但是在效率方面，处理加锁的机制会让数据库产生额外的开销，还有增加产生死锁的机会；另外，在只读型事务处理中由于不会产生冲突，也没必要使用锁，这样做只能增加系统负载；还有会降低了并行性，一个事务如果锁定了某行数据，其他事务就必须等待该事务处理完才可以处理那行数

**优点：**
适合在写多读少的并发环境中使用，虽然无法维持非常高的性能，但是在乐观锁无法提更好的性能前提下，可以做到数据的安全性
**缺点：**
加锁会增加系统开销，虽然能保证数据的安全，但数据处理吞吐量低，不适合在读书写少的场合下使用

### 什么是乐观锁？

在关系数据库管理系统里，乐观并发控制（又名“乐观锁”，Optimistic Concurrency Control，缩写“OCC”）是一种并发控制的方法；乐观锁（ Optimistic Locking ） 是相对悲观锁而言，乐观锁是假设认为即使在并发环境中，外界对数据的操作一般是不会造成冲突，所以并不会去加锁(所以乐观锁不是一把锁)，而是在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则让返回冲突信息，让用户决定如何去做下一步，比如说重试，直至成功为止；数据库的乐观锁，并不是利用数据库本身的锁去实现的，可能是利用某种实现逻辑去实现做到乐观锁的思想

数据库的乐观并发控制要解决的是数据库并发场景下的写-写冲突，指在用无锁的方式去解决

**数据库中乐观锁的实现**
通常乐观锁的实现有两种，但它们的内在都是CAS思想的设计：

- 方式一： 使用数据版本（version）实现

  > 这是乐观锁最常用的一种实现方式。什么是数据版本呢？就是在表中增添一个字段作为该记录的版本标识 ，比如叫version，每次对该记录的写操作都会让 version+ 1。
  > 所以当我们读取了数据(包括version)，做出更新，要提交的时候，就会拿取得的version去跟数据库中的version比较是否一致，如果一致则代表这个时间段，并没有其他的线程的也修改过这个数据，给予更新，同时version + 1；如果不一致，则代表在这个时间段，该记录以及被其他线程修改过了， 认为是过期数据，返回冲突信息，让用户决定下一步动作，比如重试（重新读取最新数据，再过更新）
  > update table set num = num + 1 , version = version + 1 where version = #{version} and id = #{id}

- 方式二： 使用时间戳(timestamp)实现

  > 表中增加一个字段，名称无所谓，比如叫update_time, 字段类型使用时间戳（timesta mp）
  > 原理和方式一一致，也是在更新提交的时检查当前数据库中数据的时间戳和自己更新前取到的时间戳是否一致，如果一致则代表此刻没有冲突，可以提交更新，同时时间戳更新为当前时间，否则就是该时间段有其他线程也更新提交过，返回冲突信息，等待用户下一步动作。
  > update table set num = num + 1 ,update_time = unix_timestamp(now()) where id = #{id} and update_time = #{updateTime}
  > 但是我们要注意的是，要实现乐观锁的思想的同时，我们必须要要保证CAS多个操作的原子性，即获取数据库数据的版本，拿数据库的数据版本与之前拿到的版本的比较，以及更新数据等这几个操作的执行必须是连贯执行，具有复合操作的原子性；所以如果是数据库的SQL,那么我们就要保证多个SQL操作处于同一个事务中

**优点与缺点**
**优点：**
在读多写少的并发场景下，可以避免数据库加锁的开销，提高Dao层的响应性能
其实很多情况下，我们orm工具都有带有乐观锁的实现，所以这些方法不一定需要我们人为的去实现

**缺点：**
在写多读少的并发场景下，即在写操作竞争激烈的情况下，会导致CAS多次重试，冲突频率过高，导致开销比悲观锁更高

### MVCC多版本并发控制

MVCC在MySQL InnoDB中的实现主要是为了提高数据库并发性能，用更好的方式去处理读-写冲突，做到即使有读写冲突时，也能做到不加锁，非阻塞并发读

**MySQL InnoDB下的当前读和快照读:**

- 当前读

  > 像select lock in share mode(共享锁), select for update ; update, insert ,delete(排他锁)这些操作都是一种当前读，为什么叫当前读？就是它读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁

- 快照读

  > 像不加锁的select操作就是快照读，即不加锁的非阻塞读；快照读的前提是隔离级别不是串行级别，串行级别下的快照读会退化成当前读；之所以出现快照读的情况，是基于提高并发性能的考虑，快照读的实现是基于多版本并发控制，即MVCC,可以认为MVCC是行锁的一个变种，但它在很多情况下，避免了加锁操作，降低了开销；既然是基于多版本，即快照读可能读到的并不一定是数据的最新版本，而有可能是之前的历史版本

说白了快照读就是MVCC思想在MySQL的具体非阻塞读功能实现，整个MVCC多并发控制的目的就是为了实现读-写冲突不加锁，提高并发读写性能，而这个读指的就是快照读, 而非当前读，当前读实际上是一种加锁的操作，是悲观锁的实现

**总结**
乐观锁和悲观锁的抉择
对乐观锁和悲观锁的抉择主要体现在写-写
在悲观锁和乐观锁的抉择中，我们可以从下面三个因素来考虑：

- 响应速度： 如果Dao层需要非常高的响应速度，尤其是**读多写少的场景下，那我们就可以采用乐观锁方案**，降低数据库锁的开销，提供并发量
- 冲突频率： **如果冲突频率非常高，那么我们就可以采用悲观锁**，保证成功率；毕竟如果冲突频率大，乐观锁会需要多次重试才能成功，代价可能会大大增加
- 重试代价： 如果重试代价大，比如说重试过程的代码执行非常耗时，那么此时我就不建议使用乐观锁了，还不如直接上悲观锁来了爽快  

**OCC,PCC,MVCC三者的关系**

- 悲观并发控制（PCC）是一种用来解决读-写冲突和写-写冲突的的加锁并发控制, 为每个操作都加锁，同一时间下，只有获得该锁的事务才能有权利对该数据进行操作，没有获得锁的事务只能等待其他事务释放锁；所以可以解决脏读，幻读，不可重复读，第一类更新丢失，第二类更新丢失的问题
- 乐观并发控制（OCC）是一种用来解决写-写冲突的无锁并发控制，认为事务间争用没有那么多，所以先进行修改，在提交事务前，检查一下事务开始后，有没有新提交改变，如果没有就提交，如果有就放弃并重试。乐观并发控制类似自旋锁。乐观并发控制适用于低数据争用，写冲突比较少的环境；无法解决脏读，幻读，不可重复读，但是可以解决更新丢失问题
- 多版本并发控制（MVCC）是一种用来解决读-写冲突的无锁并发控制，也就是**为事务分配单向增长的时间戳，为每个修改保存一个版本，版本与事务时间戳关联，读操作只读该事务开始前的数据库的快照。** 这样在读操作时就不用阻塞写操作，写操作也不用阻塞读操作；不仅可以提高并发性能，还可以解决脏读，幻读，不可重复读等事务问题。更新丢失问题除外

总的来说，MVCC的出现就是数据库不满用悲观锁去解决读-写冲突问题，因性能不高而提出的解决方案，所以在数据库中，我们可以形成两个组合：

**MVCC + 悲观锁**
MVCC解决读写冲突，悲观锁解决写写冲突
**MVCC + 乐观锁**
MVCC解决读写冲突，乐观锁解决写写冲突
这种组合的方式就可以最大程度的提高数据库并发性能，并解决读写冲突，和写写冲突导致的问题

## 回表查询

那回表是什么：如果是通过非主键索引进行查询，select所要获取的字段不能通过非主键索引获取到，需要通过非主键索引获取到的主键，从聚集索引再次查询一遍，获取到所要查询的记录，这个查询的过程就是回表

[![img](https://img2018.cnblogs.com/blog/885859/201907/885859-20190729184808306-758660222.png)](https://img2018.cnblogs.com/blog/885859/201907/885859-20190729184808306-758660222.png)

两个B+树索引分别如上图：

　　（1）id为PK，聚集索引，叶子节点存储行记录；

　　（2）name为KEY，普通索引，叶子节点存储PK值，即id；

既然从普通索引无法直接定位行记录，那**普通索引的查询过程是怎么样的呢？**

通常情况下，需要扫码两遍索引树。

例如：

```
select` `* ``from` `t ``where` `name``=``'lisi'``;　
```

**是如何执行的呢？**

[![img](https://img2018.cnblogs.com/blog/885859/201907/885859-20190729184911699-676257427.png)](https://img2018.cnblogs.com/blog/885859/201907/885859-20190729184911699-676257427.png)

如**粉红色**路径，需要扫码两遍索引树：

（1）先通过普通索引定位到主键值id=5；

（2）在通过聚集索引定位到行记录；

这就是所谓的**回表查询**，先定位主键值，再定位行记录，它的性能较扫一遍索引树更低。
