# 虚拟内存

虚拟内存设计的背景：

1. 进程映像包括程序代码、数据和PCB，这些都需要占据物理内存。
2. 有可能一个进程运行所需的程序代码和数据完全超过了物理内存的大小，更何况操作系统中同时有多个进程，而且物理内存需要存储其他信息。
3. 这时候，可以根据**程序的局部性原理**，先将一部分的程序和数据加载到物理内存中，剩余部分放在磁盘上。
4. 有需要的时候，再从磁盘加载其他部分；如果物理内存不够，还可以将已经加载到物理内存的部分换出，为加载其他部分腾出空间。
5. 而且，希望这样的换入换出对用户来说是透明。给用户一种内存很大，无需担心小而有限的内存容量给程序设计带来限制的安全感。

虚拟内存的实质：

1. 将进程的地址空间叫做虚拟地址空间，对这片空间进行分块，每个块叫做一个页。
2. 使用某些机制，如分页机制、分段机制、段页式机制，将每个页映射到物理内存中，即将虚拟地址映射为物理地址。
3. 这样进程访问的是虚拟地址，内部会被转化成存储了代码或数据的物理地址，从而访问到想要的代码或数据。
4. 并且，这些页不需要被映射到连续的物理内存，也不需要所有页都在物理内存中。
5. 当进程引用不到物理内存中的页时，操作系统和硬件执行一些列操作，将缺失的部分装入物理内存，并重新执行失败的指令。
6. 优点： 通过使用虚拟内存技术，可以将物理内存扩大成更大的虚拟内存，从而不用担心小容量的内存对程序设计的限制。
6. 保护每个进程的地址空间不被其他进程破坏，隔离了进程的地址访问

如何实现虚拟内存？
通过分页、分段、段页式三种机制，实现虚拟内存。

# 进程与线程

## 区别

##### 1. 基本概念：

进程是对运行时程序的封装，是**系统进行资源调度和分配的的基本单位，实现了操作系统的并发**；

线程是进程的子任务，**是CPU调度和分派的基本单位**，**用于保证程序的实时性，实现进程内部的并发；线程是操作系统可识别的最小执行和调度单位**。每个线程都独自占用一个**虚拟处理器**：独自的**寄存器组**，**指令计数器和处理器状态**。每个线程完成不同的任务，但是**共享同一地址空间**（也就是同样的**动态内存，映射文件，目标代码等等**），**打开的文件队列和其他内核资源**。

##### 2. 区别：

1.  **一个线程只能属于一个进程，而一个进程可以有多个线程**，但至少有一个线程。线程依赖于进程而存在。 

2.  **进程在执行过程中拥有独立的内存单元，而多个线程共享进程的内存**。（资源分配给进程，同一进程的所有线程共享该进程的所有资源。同一进程中的多个线程共享代码段（代码和常量），数据段（全局变量和静态变量），扩展段（堆存储）。但是每个线程拥有自己的栈段，栈段又叫运行时段，用来存放所有局部变量和临时变量。） 

3.  **进程是资源分配的最小单位，线程是CPU调度的最小单位**； 

4.  系统开销： 由于在创建或撤消进程时，系统都要为之分配或回收资源，如内存空间、I／o设备等。因此，操作系统所付出的开销将显著地大于在创建或撤消线程时的开销。类似地，在进行进程切换时，涉及到整个当前进程CPU环境的保存以及新被调度运行的进程的CPU环境的设置。而线程切换只须保存和设置少量寄存器的内容，并不涉及存储器管理方面的操作。可见，**进程切换的开销也远大于线程切换的开销**。 

5.  通信：由于同一进程中的多个线程具有相同的地址空间，致使它们之间的同步和通信的实现，也变得比较容易。**进程间通信IPC，线程间可以直接读写进程数据段（如全局变量）来进行通信——需要进程同步和互斥手段的辅助，以保证数据的一致性**。在有的系统中，线程的切换、同步和通信都无须操作系统内核的干预 

6.  **进程编程调试简单可靠性高，但是创建销毁开销大；线程正相反，开销小，切换速度快，但是编程调试相对复杂**。 

7.  **进程间不会相互影响 ；线程一个线程挂掉将导致整个进程挂掉** 

8.  **进程适应于多核、多机分布；线程适用于多核**

   

## 进程间通讯

##### 进程间通信的方式：

进程间通信主要包括**管道、系统IPC（包括**[**消息队列**](https://cloud.tencent.com/product/cmq?from=10680)**、信号量、信号、共享内存等）、以及套接字socket**。

**1.管道：**

管道主要包括**匿名管道和命名管道**:管道可用于具有亲缘关系的父子进程间的通信，命名管道除了具有管道所具有的功能外，它还允许无亲缘关系进程间的通信

- 1.1 **匿名管道PIPE**：

1. 它是**半双工**的（即数据只能在一个方向上流动），具有固定的读端和写端
2. 它**只能用于具有亲缘关系的进程之间的通信**（也是父子进程或者兄弟进程之间）
3. 它可以看成是一种特殊的文件，**对于它的读写也可以使用普通的read、write等函数**。但是它不是普通的文件，并不属于其他任何文件系统，并且只存在于内存中。

- 1.2 **命名管道FIFO：**

1. FIFO**可以在无关的进程之间交换数据**
2. FIFO有路径名与之相关联，它**以一种特殊设备文件形式存在于文件系统中**。

**2. 系统IPC：**

- 2.1 **消息队列**

  消息队列，**是消息的链接表，存放在内核中**。一个消息队列由一个标识符（即队列ID）来标记。 (**消息队列克服了信号传递信息少，管道只能承载无格式字节流以及缓冲区大小受限等特点**)具有写权限得进程可以按照一定得规则向消息队列中添加新信息；对消息队列有读权限得进程则可以从消息队列中读取信息；

特点：

1. 消息队列是**面向记录的**，其中的消息具有特定的格式以及特定的优先级。
2. 消息队列**独立于发送与接收进程**。进程终止时，消息队列及其内容并不会被删除。
3. 消息队列**可以实现消息的随机查询**,消息不一定要以先进先出的次序读取,也可以按消息的类型读取。

- **2.2 信号量semaphore** 

  信号量（semaphore）与已经介绍过的 IPC 结构不同，它是一个**计数器，可以用来控制多个进程对共享资源的访问**。信号量用于实现进程间的互斥与同步，而不是用于存储进程间通信数据。

特点：

1. 信号量用于**进程间同步**，若要在进程间传递数据需要结合共享内存。
2. 信号量**基于操作系统的 PV 操作**，程序对信号量的操作都是原子操作。
3. **每次对信号量的 PV 操作不仅限于对信号量值加 1 或减 1，而且可以加减任意正整数**。
4. **支持信号量组**。

**2.3 信号signal**

信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。

**2.4 共享内存（Shared Memory）**

它使得**多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据得更新**。这种方式需要依靠某种同步操作，如互斥锁和信号量等

特点：

1. 共享内存是最快的一种IPC，因为进程是直接对内存进行存取
2. 因为多个进程可以同时操作，所以需要进行同步
3. 信号量+共享内存通常结合在一起使用，信号量用来同步对共享内存的访问

**3.套接字SOCKET：**

socket也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同主机之间的进程通信。

### 线程间通信的方式: 

1. 对于多线程访问共享资源出现数据混乱的问题，需要进行线程同步。所谓的共享资源就是多个线程共同访问的变量，这些变量通常为全局数据区变量或者堆区变量，这些变量对应的共享资源也被称之为临界资源。

   > 常用的线程同步方式有四种：互斥锁、读写锁、条件变量、信号量。

   1. **互斥锁**
      互斥锁是线程同步最常用的一种方式，通过互斥锁可以锁定一个代码块，对于被锁定的这个代码块，所有的线程只能串行处理，不能并行处理。

   - 相关函数：

   ``` c++
   int pthread_mutex_init(pthread_mutex_t *restrict mutex, 
                           const pthread_mutexattr_t *restrict attr);
   int pthread_mutex_destroy(pthread_mutex_t *mutex);
   int pthread_mutex_lock(pthread_mutex_t *mutex);
   int pthread_mutex_trylock(pthread_mutex_t *mutex);
   int pthread_mutex_unlock(pthread_mutex_t *mutex);
                       //所有函数成功返回0，出错返回错误编号
   ```


   在使用互斥量之前需要对它进行初始化，然后调用 pthread_mutex_lock 对互斥量上锁，若互斥量已经上锁，调用线程将阻塞直到互斥量被解锁，如果不希望线程被阻塞，可以调用 pthread_mutex_trylock 尝试对互斥量进行加锁，最后调用 pthread_mutex_unlock 对互斥量解锁。

   2. **读写锁**
      读写锁是互斥锁的升级版，所有线程的读操作都是并行的，只有写操作是串行的。程序中的读操作越多，读写锁性能就越高，相反，若程序中全是写操作，那么读写锁会退化成互斥锁。

   - 相关函数：

   ``` c++
   int pthread_rwlock_init(pthread_rwlock_t *restrict rwlock,
                               const pthread_rwlockattr_t *restrict attr);
   int pthread_rwlock_destroy(pthread_rwlock_t *rwlock);
   int pthread_rwlock_rdlock(pthread_rwlock_t *rwlock);
   int pthread_rwlock_wrlock(pthread_rwlock_t *rwlock);
   int pthread_rwlock_unlock(pthread_rwlock_t *rwlock);
                       //成功返回0，出错返回错误编号
   ```


   可以指定加读锁或者写锁，不管以何种方式锁住读写锁，都可以调用 pthread_rwlock_unlock 进行解锁。

   3. **条件变量**
      条件变量的主要作用不是处理线程同步，而是进行线程的阻塞。常常和互斥锁一起用在生产者和消费者模型中。举个例子：当任务队列为空时，消费者无法消费，使用条件变量把消费者线程阻塞住，等待生产者生产出任务后，再唤醒一个或多个被条件变量阻塞的消费者线程；反过来也可以控制生产者生产的上限，当任务队列达到一个上限值时用条件变量阻塞住生产者线程，直到消费者把任务消费后再唤醒被条件变量阻塞的生产者线程。

   - 相关函数：

   ```c++
   int pthread_cond_init(pthread_cond_t *restrict cond,
                           const pthread_condattr_t *restrict attr);
   int pthread_cond_destroy(pthread_cond_t *cond);
   int pthread_cond_wait(pthread_cond_t *restrict cond, pthread_mutex_t *restrict mutex);
   int pthread_cond_signal(pthread_cond_t *cond);
   int pthread_cond_broadcast(pthread_cond_t *cond);
                       //成功返回0，出错返回错误编号
   ```

   4. **信号量**
      信号量可以实现线程同步也可以实现进程同步，它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目。信号量主要阻塞线程，不能完全保证线程安全，如果要保证线程安全，需要和互斥锁一起使用。信号量也可以用来实现生产者消费者模型，在用条件变量实现生产者消费者模型时需要自己做条件判断，而使用信号量就不需要。举个例子：初始化生产者的信号量为5，消费者的信号量为0，因为消费者信号量为0所以会被阻塞，生产者进行一次生产后会将自己的信号量减1，将消费者信号量加1，这时消费者解除阻塞，进行消费后再将自己的信号量减1生产者信号量加1。

   - 相关函数：

     ``` c++
     int sem_init(sem_t* sem, int pshared, unsigned int value);  //信号量对象地址，是否多进程共享，初始状态下资源数量
     int sem_destroy(sem_t* sem);    //销毁信号量
     int sem_post(sem_t* sem);       //将信号量资源计数递增1并唤醒线程
     int sem_wait(sem_t* sem);       //若当前信号量为0，则阻塞线程，直到信号量对象的资源计数大于0时被唤醒，唤醒后资源计数递减1
     int sem_trywait(sem_t* sem);    //非阻塞版本
     int sem_timedwait(sem_t* sem, const struct timespec* abs_timeout);  //带等待时间的版本
     ```

   5) **自旋锁**
      自旋锁与互斥锁类似，但它不是通过休眠使进程阻塞，而是在获取锁之前一直处于忙等（自旋）阻塞状态。自旋锁可用于一下情况：锁被持有的时间短，而且线程并不希望在重新调度上花费太多成本。

   - 相关函数：

     ```c++
     int pthread_spin_init(pthread_spinlock_t *lock, int pshared);
     int pthread_spin_destroy(pthread_spinlock_t *lock);
     int pthread_spin_lock(pthread_spinlock_t *lock);
     int pthread_spin_trylock(pthread_spinlock_t *lock);
     int pthread_spin_unlock(pthread_spinlock_t *lock);
                         //成功返回0，出错返回错误编号
     ```

   6)  **屏障**
       屏障允许每个线程等待，直到所有的合作线程都到达某一点，然后从该点继续执行。pthread_join函数就是一种屏障，允许一个线程等待，直到另一个线程退出，但屏障允许任意数量的线程等待，直到所有的线程完成处理工作，而线程不需要退出，所有线程达到屏障后可以接着工作。

   - 函数原型：

     ```c++
     int pthread_barrier_init(pthread_barrier_t *restrict barrier,
             const pthread_barrierattr_t *restrict attr, unsigned int count);
     int pthread_barrier_destroy(pthread_barrier_t *barrier);
     int pthread_barrier_wait(pthread_barrier_t *barrier);
                         //成功返回0，出错返回错误编号
     ```

     count指定在允许所有线程继续运行之前，必须到达屏障的线程数目；
     调用pthread_barrier_wait的线程在屏障计数，未满足条件时会进入休眠状态。如果该线程是最后一个调用pthread_barrier_wait的线程，就满足了屏障计数，所有的线程都被唤醒。

## 进程与线程上下文切换

**进程上下文切换开销都有哪些**

那么上下文切换的时候，CPU的开销都具体有哪些呢？开销分成两种，一种是直接开销、一种是间接开销。

直接开销就是在切换时，cpu必须做的事情，包括：

1. 切换**页表**全局目录

2. 切换**内核态堆栈**

3. 切换**硬件上下文**（进程恢复前，必须装入寄存器的数据统称为硬件上下文）

- **ip**(instruction pointer)：指向当前执行指令的下一条指令

- **bp**(base pointer): 用于存放执行中的函数对应的栈帧的栈底地址
- **sp**(stack poinger): 用于存放执行中的函数对应的栈帧的栈顶地址
- **cr3**:页目录基址寄存器，保存页目录表的物理地址
- ......

4. 刷新**TLB**

5. 系统调度器的代码执行

**间接开销**

主要指的是虽然切换到一个新进程后，由于各种缓存并不热，速度运行会慢一些。如果进程始终都在一个CPU上调度还好一些，如果跨CPU的话，之前热起来的TLB、L1、L2、L3因为运行的进程已经变了，所以以局部性原理cache起来的代码、数据也都没有用了，导致新进程穿透到内存的IO会变多。 其实我们上面的实验并没有很好地测量到这种情况，所以实际的上下文切换开销可能比3.5us要大。

**为什么进程切换比线程切换耗费资源？**

进程切换分两步
**1. 切换页目录以使用新的地址空间。**
**2. 切换内核栈和硬件上下文。**

对于linux来说，线程和进程的最大区别就在于地址空间。


对于**线程切换，第1步是不需要做的，第2是进程和线程切换都要做的**。所以明显是进程切换代价大。内核的这种切换过程伴随的最显著的性能损耗是将寄存器中的内容切换出。

每个进程都有对应的页表，进程切换的时候需要切换页表，为了加快虚拟地址的地址转换效率，所以引入了**TLB来缓存对应的虚拟地址和物理地址的映射。**

切换页表这个操作本身是不太耗费时间的，切换之后，TLB就失效了，所以在进行地址转化的时候需要重新去查找页表，这就造成了程序运行的效率低下。

同一个进程的线程之间是共用一个页表的，所以线程之间的切换是不需要切换页表的。

**线程上下文切换**

线程与进程最大的区别在于：**线程是调度的基本单位，而进程则是资源拥有的基本单位**。说白了，所谓内核中的任务调度，实际上的调度对象是线程；而进程只是给线程提供了虚拟内存、全局变量等资源。

所以，对于线程和进程，我们可以这么理解： 

- 当进程只有一个线程时，可以认为进程就等于线程。 
-  当进程拥有多个线程时，这些线程会**共享相同的虚拟内存和全局变量等资源。**这些资源在上下文切换时是不需要修改的。 - 另外，**线程也有自己的私有数据，比如栈和寄存器等**，这些在上下文切换时也是需要保存的。

**发生线程上下文切换的场景**

1. 前后两个线程属于不同进程。此时，因为资源不共享，所以切换过程就跟进程上下文切换是一样。
2. 前后两个线程属于同一个进程。此时，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据

# TLB工作原理

TLB - translation lookaside buffer

快表，直译为旁路快表缓冲，也可以理解为页表缓冲，地址变换高速缓存。

由于页表存放在主存中，因此程序每次访存至少需要两次：一次访存获取物理地址，第二次访存才获得数据。提高访存性能的关键在于依靠页表的访问局部性。当一个转换的虚拟页号被使用时，它可能在不久的将来再次被使用到，。

**TLB是一种高速缓存，内存管理硬件使用它来改善虚拟地址到物理地址的转换速度。**当前所有的个人桌面，笔记本和服务器处理器都使用**TLB来进行虚拟地址到物理地址的映射。**使用TLB内核可以快速的找到虚拟地址指向物理地址，而不需要请求RAM内存获取虚拟地址到物理地址的映射关系。

# 进程调度/页面置换/磁盘调度算法

<img src="https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95%E6%8F%90%E7%BA%B2.png" alt="本文提纲" style="zoom: 33%;" />

### 进程调度算法

进程调度算法也称 CPU 调度算法，毕竟进程是由 CPU 调度的。

当 CPU 空闲时，操作系统就选择内存中的某个「就绪状态」的进程，并给其分配 CPU。

什么时候会发生 CPU 调度呢？通常有以下情况：

1. 当进程从运行状态转到等待状态；
2. 当进程从运行状态转到就绪状态；
3. 当进程从等待状态转到就绪状态；
4. 当进程从运行状态转到终止状态；

其中发生在 1 和 4 两种情况下的调度称为「非抢占式调度」，2 和 3 两种情况下发生的调度称为「抢占式调度」。

非抢占式的意思就是，当进程正在运行时，它就会一直运行，直到该进程完成或发生某个事件而被阻塞时，才会把 CPU 让给其他进程。

而抢占式调度，顾名思义就是进程正在运行的时，可以被打断，使其把 CPU 让给其他进程。那抢占的原则一般有三种，分别是时间片原则、优先权原则、短作业优先原则。

你可能会好奇为什么第 3 种情况也会发生 CPU 调度呢？假设有一个进程是处于等待状态的，但是它的优先级比较高，如果该进程等待的事件发生了，它就会转到就绪状态，一旦它转到就绪状态，如果我们的调度算法是以优先级来进行调度的，那么它就会立马抢占正在运行的进程，所以这个时候就会发生 CPU 调度。

那第 2 种状态通常是时间片到的情况，因为时间片到了就会发生中断，于是就会抢占正在运行的进程，从而占用 CPU。

调度算法影响的是等待时间（进程在就绪队列中等待调度的时间总和），而不能影响进程真在使用 CPU 的时间和 I/O 时间。

#### 先来先服务调度算法

最简单的一个调度算法，就是非抢占式的**先来先服务（First Come First Severd, FCFS）算法**了。

<img src="https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/24-%E5%85%88%E6%9D%A5%E5%85%88%E6%9C%8D%E5%8A%A1.jpg" alt="FCFS 调度算法" style="zoom:50%;" />FCFS 调度算法

顾名思义，先来后到，**每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。**

这似乎很公平，但是当一个长作业先运行了，那么后面的短作业等待的时间就会很长，不利于短作业。

FCFS 对长作业有利，适用于 CPU 繁忙型作业的系统，而不适用于 I/O 繁忙型作业的系统。

#### 最短作业优先调度算法

**最短作业优先（Shortest Job First, SJF）调度算法**同样也是顾名思义，它会**优先选择运行时间最短的进程来运行**，这有助于提高系统的吞吐量。

<img src="https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/25-%E6%9C%80%E7%9F%AD%E4%BD%9C%E4%B8%9A%E4%BC%98%E5%85%88%E7%AE%97%E6%B3%95.jpg" alt="SJF 调度算法" style="zoom:50%;" />

这显然对长作业不利，很容易造成一种极端现象。

比如，一个长作业在就绪队列等待运行，而这个就绪队列有非常多的短作业，那么就会使得长作业不断的往后推，周转时间变长，致使长作业长期不会被运行。

#### 高响应比优先调度算法

前面的「先来先服务调度算法」和「最短作业优先调度算法」都没有很好的权衡短作业和长作业。

那么，**高响应比优先 （\*Highest Response Ratio Next, HRRN\*）调度算法**主要是权衡了短作业和长作业。

**每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行**，「响应比优先级」的计算公式：

<img src="https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/26-%E5%93%8D%E5%BA%94%E6%AF%94%E5%85%AC%E5%BC%8F.jpg" alt="img" style="zoom:50%;" />

从上面的公式，可以发现：

- 如果两个进程的「等待时间」相同时，「要求的服务时间」越短，「响应比」就越高，这样短作业的进程容易被选中运行；
- 如果两个进程「要求的服务时间」相同时，「等待时间」越长，「响应比」就越高，这就兼顾到了长作业进程，因为进程的响应比可以随时间等待的增加而提高，当其等待时间足够长时，其响应比便可以升到很高，从而获得运行的机会；

#### 时间片轮转调度算法

最古老、最简单、最公平且使用最广的算法就是**时间片轮转（\*Round Robin, RR\*）调度算法**。
。

<img src="https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/27-%E6%97%B6%E9%97%B4%E7%89%87%E8%BD%AE%E8%AF%A2.jpg" alt="RR 调度算法" style="zoom:50%;" />RR 调度算法

**每个进程被分配一个时间段，称为时间片（\*Quantum\*），即允许该进程在该时间段中运行。**

- 如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配另外一个进程；
- 如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换；

另外，时间片的长度就是一个很关键的点：

- 如果时间片设得太短会导致过多的进程上下文切换，降低了 CPU 效率；
- 如果设得太长又可能引起对短作业进程的响应时间变长。将

通常时间片设为 `20ms~50ms` 通常是一个比较合理的折中值。

#### 最高优先级调度算法

前面的「时间片轮转算法」做了个假设，即让所有的进程同等重要，也不偏袒谁，大家的运行时间都一样。

但是，对于多用户计算机系统就有不同的看法了，它们希望调度是有优先级的，即希望调度程序能**从就绪队列中选择最高优先级的进程进行运行，这称为最高优先级（Highest Priority First，HPF）调度算法**。

进程的优先级可以分为，静态优先级或动态优先级：

- 静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化；
- 动态优先级：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是**随着时间的推移增加等待进程的优先级**。

该算法也有两种处理优先级高的方法，非抢占式和抢占式：

- 非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程。
- 抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行。

但是依然有缺点，可能会导致低优先级的进程永远不会运行。

#### 多级反馈队列调度算法

**多级反馈队列（\*Multilevel Feedback Queue\*）调度算法**是「时间片轮转算法」和「最高优先级算法」的综合和发展。

顾名思义：

- 「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。
- 「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列；

<img src="https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/28-%E5%A4%9A%E7%BA%A7%E9%98%9F%E5%88%97.jpg" alt="多级反馈队列" style="zoom:50%;" />

- 设置了多个队列，赋予每个队列不同的优先级，每个**队列优先级从高到低**，同时**优先级越高时间片越短**；
- 新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成；
- 当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行；

可以发现，对于短作业可能可以在第一级队列很快被处理完。对于长作业，如果在第一级队列处理不完，可以移入下次队列等待被执行，虽然等待的时间变长了，但是运行时间也会更长了，所以该算法很好的**兼顾了长短作业，同时有较好的响应时间。**

------

### 内存页面置换算法

在了解内存页面置换算法前，我们得先谈一下**缺页异常（缺页中断）**。

当 CPU 访问的页面不在物理内存时，便会产生一个缺页中断，请求操作系统将所缺页调入到物理内存。那它与一般中断的主要区别在于：

- 缺页中断在指令执行「期间」产生和处理中断信号，而一般中断在一条指令执行「完成」后检查和处理中断信号。
- 缺页中断返回到该指令的开始重新执行「该指令」，而一般中断返回回到该指令的「下一个指令」执行。

我们来看一下缺页中断的处理流程，如下图：

<img src="https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/%E7%BC%BA%E9%A1%B5%E5%BC%82%E5%B8%B8%E6%B5%81%E7%A8%8B.png" alt="缺页中断的处理流程" style="zoom:50%;" />

1. 在 CPU 里访问一条 Load M 指令，然后 CPU 会去找 M 所对应的页表项。
2. 如果该页表项的状态位是「有效的」，那 CPU 就可以直接去访问物理内存了，如果状态位是「无效的」，则 CPU 则会发送缺页中断请求。
3. 操作系统收到了缺页中断，则会执行缺页中断处理函数，先会查找该页面在磁盘中的页面的位置。
4. 找到磁盘中对应的页面后，需要把该页面换入到物理内存中，但是在换入前，需要在物理内存中找空闲页，如果找到空闲页，就把页面换入到物理内存中。
5. 页面从磁盘换入到物理内存完成后，则把页表项中的状态位修改为「有效的」。
6. 最后，CPU 重新执行导致缺页异常的指令。

上面所说的过程，第 4 步是能在物理内存找到空闲页的情况，那如果找不到呢？

找不到空闲页的话，就说明此时内存已满了，这时候，就需要「页面置换算法」选择一个物理页，如果该物理页有被修改过（脏页），则把它换出到磁盘，然后把该被置换出去的页表项的状态改成「无效的」，最后把正在访问的页面装入到这个物理页中。

这里提一下，页表项通常有如下图的字段：

<img src="https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/%E9%A1%B5%E8%A1%A8%E9%A1%B9%E5%AD%97%E6%AE%B5.png" alt="img" style="zoom:50%;" />

那其中：

- *状态位*：用于表示该页是否有效，也就是说是否在物理内存中，供程序访问时参考。
- *访问字段*：用于记录该页在一段时间被访问的次数，供页面置换算法选择出页面时参考。
- *修改位*：表示该页在调入内存后是否有被修改过，由于内存中的每一页都在磁盘上保留一份副本，因此，如果没有修改，在置换该页时就不需要将该页写回到磁盘上，以减少系统的开销；如果已经被修改，则将该页重写到磁盘上，以保证磁盘中所保留的始终是最新的副本。
- *硬盘地址*：用于指出该页在硬盘上的地址，通常是物理块号，供调入该页时使用。

这里我整理了虚拟内存的管理整个流程，你可以从下面这张图看到：

<img src="https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%B5%81%E7%A8%8B.png" alt="虚拟内存的流程" style="zoom:50%;" />虚拟内存的流程

所以，页面置换算法的功能是，**当出现缺页异常，需调入新页面而内存已满时，选择被置换的物理页面**，也就是说选择一个物理页面换出到磁盘，然后把需要访问的页面换入到物理页。

那其算法目标则是，尽可能减少页面的换入换出的次数，常见的页面置换算法有如下几种：

- 最佳页面置换算法（*OPT*）
- 先进先出置换算法（*FIFO*）
- 最近最久未使用的置换算法（*LRU*）
- 时钟页面置换算法（*Lock*）
- 最不常用置换算法（*LFU*）

#### 最佳页面置换算法

最佳页面置换算法基本思路是，**置换在「未来」最长时间不访问的页面**。

所以，该算法实现需要计算内存中每个逻辑页面的「下一次」访问时间，然后比较，选择未来最长时间不访问的页面。

我们举个例子，假设一开始有 3 个空闲的物理页，然后有请求的页面序列，那它的置换过程如下图：

<img src="https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/%E6%9C%80%E4%BC%98%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95.png" alt="最佳页面置换算法" style="zoom:50%;" />最佳页面置换算法

在这个请求的页面序列中，缺页共发生了 `7` 次（空闲页换入 3 次 + 最优页面置换 4 次），页面置换共发生了 `4` 次。

这很理想，但是实际系统中无法实现，因为程序访问页面时是动态的，我们是无法预知每个页面在「下一次」访问前的等待时间。

所以，最佳页面置换算法作用是为了衡量你的算法的效率，你的算法效率越接近该算法的效率，那么说明你的算法是高效的。

#### 先进先出置换算法

既然我们无法预知页面在下一次访问前所需的等待时间，那我们可以**选择在内存驻留时间很长的页面进行中置换**，这个就是「先进先出置换」算法的思想。

还是以前面的请求的页面序列作为例子，假设使用先进先出置换算法，则过程如下图：

<img src="https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/FIFO%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95.png" alt="先进先出置换算法" style="zoom:50%;" />先进先出置换算法

在这个请求的页面序列中，缺页共发生了 `10` 次，页面置换共发生了 `7` 次，跟最佳页面置换算法比较起来，性能明显差了很多。

#### 最近最久未使用的置换算法

最近最久未使用（*LRU*）的置换算法的基本思路是，发生缺页时，**选择最长时间没有被访问的页面进行置换**，也就是说，该算法假设已经很久没有使用的页面很有可能在未来较长的一段时间内仍然不会被使用。

这种算法近似最优置换算法，最优置换算法是通过「未来」的使用情况来推测要淘汰的页面，而 LRU 则是通过「历史」的使用情况来推测要淘汰的页面。

还是以前面的请求的页面序列作为例子，假设使用最近最久未使用的置换算法，则过程如下图：

<img src="https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/LRU%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95.png" alt="最近最久未使用的置换算法" style="zoom:50%;" />

最近最久未使用的置换算法

在这个请求的页面序列中，缺页共发生了 `9` 次，页面置换共发生了 `6` 次，跟先进先出置换算法比较起来，性能提高了一些。

虽然 LRU 在理论上是可以实现的，但代价很高。为了完全实现 LRU，需要在内存中维护一个所有页面的链表，最近最多使用的页面在表头，最近最少使用的页面在表尾。

困难的是，在每次访问内存时都必须要更新「整个链表」。在链表中找到一个页面，删除它，然后把它移动到表头是一个非常费时的操作。

所以，LRU 虽然看上去不错，但是由于开销比较大，实际应用中比较少使用。

#### 时钟页面置换算法

那有没有一种即能优化置换的次数，也能方便实现的算法呢？

时钟页面置换算法就可以两者兼得，它跟 LRU 近似，又是对 FIFO 的一种改进。

该算法的思路是，把所有的页面都保存在一个类似钟面的「环形链表」中，一个表针指向最老的页面。

当发生缺页中断时，算法首先检查表针指向的页面：

- 如果它的访问位位是 0 就淘汰该页面，并把新的页面插入这个位置，然后把表针前移一个位置；
- 如果访问位是 1 就清除访问位，并把表针前移一个位置，重复这个过程直到找到了一个访问位为 0 的页面为止；

我画了一副时钟页面置换算法的工作流程图，你可以在下方看到：

<img src="https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/%E6%97%B6%E9%92%9F%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95.png" alt="时钟页面置换算法" style="zoom:50%;" />时钟页面置换算法

了解了这个算法的工作方式，就明白为什么它被称为时钟（*Clock*）算法了。

#### 最不常用算法

最不常用（*LFU*）算法，这名字听起来很调皮，但是它的意思不是指这个算法不常用，而是**当发生缺页中断时，选择「访问次数」最少的那个页面，并将其淘汰**。

它的实现方式是，对每个页面设置一个「访问计数器」，每当一个页面被访问时，该页面的访问计数器就累加 1。在发生缺页中断时，淘汰计数器值最小的那个页面。

看起来很简单，每个页面加一个计数器就可以实现了，但是在操作系统中实现的时候，我们需要考虑效率和硬件成本的。

要增加一个计数器来实现，这个硬件成本是比较高的，另外如果要对这个计数器查找哪个页面访问次数最小，查找链表本身，如果链表长度很大，是非常耗时的，效率不高。

但还有个问题，LFU 算法只考虑了频率问题，没考虑时间的问题，比如有些页面在过去时间里访问的频率很高，但是现在已经没有访问了，而当前频繁访问的页面由于没有这些页面访问的次数高，在发生缺页中断时，就会可能会误伤当前刚开始频繁访问，但访问次数还不高的页面。

那这个问题的解决的办法还是有的，可以定期减少访问的次数，比如当发生时间中断时，把过去时间访问的页面的访问次数除以 2，也就说，随着时间的流失，以前的高访问次数的页面会慢慢减少，相当于加大了被置换的概率。

## 磁盘调度算法

我们来看看磁盘的结构，如下图：

![磁盘的结构](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/%E7%A3%81%E7%9B%98%E7%BB%93%E6%9E%84.jpg)磁盘的结构

常见的机械磁盘是上图左边的样子，中间圆的部分是磁盘的盘片，一般会有多个盘片，每个盘面都有自己的磁头。右边的图就是一个盘片的结构，盘片中的每一层分为多个磁道，每个磁道分多个扇区，每个扇区是 `512` 字节。那么，多个具有相同编号的磁道形成一个圆柱，称之为磁盘的柱面，如上图里中间的样子。

磁盘调度算法的目的很简单，就是为了提高磁盘的访问性能，一般是通过优化磁盘的访问请求顺序来做到的。

寻道的时间是磁盘访问最耗时的部分，如果请求顺序优化的得当，必然可以节省一些不必要的寻道时间，从而提高磁盘的访问性能。

假设有下面一个请求序列，每个数字代表磁道的位置：

98，183，37，122，14，124，65，67

初始磁头当前的位置是在第 `53` 磁道。

接下来，分别对以上的序列，作为每个调度算法的例子，那常见的磁盘调度算法有：

- 先来先服务算法
- 最短寻道时间优先算法
- 扫描算法算法
- 循环扫描算法
- LOOK 与 C-LOOK 算法

#### 先来先服务

先来先服务（*First-Come，First-Served，FCFS*），顾名思义，先到来的请求，先被服务。

那按照这个序列的话：

98，183，37，122，14，124，65，67

那么，磁盘的写入顺序是从左到右，如下图：

![先来先服务](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/%E7%A3%81%E7%9B%98%E8%B0%83%E5%BA%A6-%E5%85%88%E6%9D%A5%E5%85%88%E6%9C%8D%E5%8A%A1.png)先来先服务

先来先服务算法总共移动了 `640` 个磁道的距离，这么一看这种算法，比较简单粗暴，但是如果大量进程竞争使用磁盘，请求访问的磁道可能会很分散，那先来先服务算法在性能上就会显得很差，因为寻道时间过长。

#### 最短寻道时间优先

最短寻道时间优先（*Shortest Seek First，SSF*）算法的工作方式是，优先选择从当前磁头位置所需寻道时间最短的请求，还是以这个序列为例子：

98，183，37，122，14，124，65，67

那么，那么根据距离磁头（ 53 位置）最近的请求的算法，具体的请求则会是下列从左到右的顺序：

65，67，37，14，98，122，124，183

![最短寻道时间优先](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/%E7%A3%81%E7%9B%98%E8%B0%83%E5%BA%A6-%E6%9C%80%E7%9F%AD%E5%AF%BB%E9%81%93%E6%97%B6%E9%97%B4%E4%BC%98%E5%85%88.png)最短寻道时间优先

磁头移动的总距离是 `236` 磁道，相比先来先服务性能提高了不少。

但这个算法可能存在某些请求的**饥饿**，因为本次例子我们是静态的序列，看不出问题，假设是一个动态的请求，如果后续来的请求都是小于 183
磁道的，那么 183 磁道可能永远不会被响应，于是就产生了饥饿现象，这里**产生饥饿的原因是磁头在一小块区域来回移动**。

#### 扫描算法

最短寻道时间优先算法会产生饥饿的原因在于：磁头有可能再一个小区域内来回得移动。

为了防止这个问题，可以规定：**磁头在一个方向上移动，访问所有未完成的请求，直到磁头到达该方向上的最后的磁道，才调换方向，这就是扫描（\*Scan\*）算法**。

这种算法也叫做电梯算法，比如电梯保持按一个方向移动，直到在那个方向上没有请求为止，然后改变方向。

还是以这个序列为例子，磁头的初始位置是 53：

98，183，37，122，14，124，65，67

那么，假设扫描调度算先朝磁道号减少的方向移动，具体请求则会是下列从左到右的顺序：

37，14，`0`，65，67，98，122，124，183

<img src="https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/%E7%A3%81%E7%9B%98%E8%B0%83%E5%BA%A6-%E6%89%AB%E6%8F%8F%E7%AE%97%E6%B3%95.png" alt="扫描算法" style="zoom:50%;" />

扫描算法

磁头先响应左边的请求，直到到达最左端（ 0 磁道）后，才开始反向移动，响应右边的请求。

扫描调度算法性能较好，不会产生饥饿现象，但是存在这样的问题，中间部分的磁道会比较占便宜，中间部分相比其他部分响应的频率会比较多，也就是说每个磁道的响应频率存在差异。

#### 循环扫描算法

扫描算法使得每个磁道响应的频率存在差异，那么要优化这个问题的话，可以总是按相同的方向进行扫描，使得每个磁道的响应频率基本一致。

循环扫描（*Circular Scan, CSCAN* ）规定：只有磁头朝某个特定方向移动时，才处理磁道访问请求，而返回时直接快速移动至最靠边缘的磁道，也就是复位磁头，这个过程是很快的，并且**返回中途不处理任何请求**，该算法的特点，就是**磁道只响应一个方向上的请求**。

还是以这个序列为例子，磁头的初始位置是 53：

98，183，37，122，14，124，65，67

那么，假设循环扫描调度算先朝磁道增加的方向移动，具体请求会是下列从左到右的顺序：

65，67，98，122，124，183，`199`，`0`，14，37

<img src="https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/%E7%A3%81%E7%9B%98%E8%B0%83%E5%BA%A6-C-SCAN%E7%AE%97%E6%B3%95.png" alt="循环扫描算法" style="zoom:50%;" />

循环扫描算法

磁头先响应了右边的请求，直到碰到了最右端的磁道 199，就立即回到磁盘的开始处（磁道 0），但这个返回的途中是不响应任何请求的，直到到达最开始的磁道后，才继续顺序响应右边的请求。

循环扫描算法相比于扫描算法，对于各个位置磁道响应频率相对比较平均。

#### LOOK 与 C-LOOK算法

我们前面说到的扫描算法和循环扫描算法，都是磁头移动到磁盘「最始端或最末端」才开始调换方向。

那这其实是可以优化的，优化的思路就是**磁头在移动到「最远的请求」位置，然后立即反向移动。**

那针对 SCAN 算法的优化则叫 LOOK 算法，它的工作方式，磁头在每个方向上仅仅移动到最远的请求位置，然后立即反向移动，而不需要移动到磁盘的最始端或最末端，**反向移动的途中会响应请求**。

![LOOK 算法](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/%E7%A3%81%E7%9B%98%E8%B0%83%E5%BA%A6-LOOK%E7%AE%97%E6%B3%95.png)LOOK 算法

而针 C-SCAN 算法的优化则叫 C-LOOK，它的工作方式，磁头在每个方向上仅仅移动到最远的请求位置，然后立即反向移动，而不需要移动到磁盘的最始端或最末端，**反向移动的途中不会响应请求**。

![C-LOOK 算法](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/%E7%A3%81%E7%9B%98%E8%B0%83%E5%BA%A6-C-LOOK%E7%AE%97%E6%B3%95.png)C-LOOK 算法